{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzWUt5aDqwS6",
        "outputId": "c0cb7c29-4ada-46a7-82a5-417b9efcd481"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------\n",
            "learning_rate=0.1, epoch=3 : 1번째 학습 실행\n",
            "Epoch [1/3], Loss: 1.6005, Train Accuracy: 62.10%\n",
            "  1. Test Accuracy: 63.57%\n",
            "Epoch [2/3], Loss: 1.2372, Train Accuracy: 59.82%\n",
            "  2. Test Accuracy: 66.88%\n",
            "Epoch [3/3], Loss: 1.5342, Train Accuracy: 49.25%\n",
            "  3. Test Accuracy: 37.57%\n",
            "Test Accuracy가 감소 : 훈련을 종료합니다. best_accuracy=66.88\n",
            "=== learning_rate=0.1 : 1번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.1, epoch=3 : 2번째 학습 실행\n",
            "Epoch [1/3], Loss: 1.7077, Train Accuracy: 55.78%\n",
            "  1. Test Accuracy: 56.44%\n",
            "Epoch [2/3], Loss: 1.4206, Train Accuracy: 52.67%\n",
            "  2. Test Accuracy: 45.74%\n",
            "Test Accuracy가 감소 : 훈련을 종료합니다. best_accuracy=56.44\n",
            "=== learning_rate=0.1 : 2번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.1, epoch=3 : 3번째 학습 실행\n",
            "Epoch [1/3], Loss: 2.0027, Train Accuracy: 50.03%\n",
            "  1. Test Accuracy: 51.43%\n",
            "Epoch [2/3], Loss: 1.4638, Train Accuracy: 47.60%\n",
            "  2. Test Accuracy: 28.24%\n",
            "Test Accuracy가 감소 : 훈련을 종료합니다. best_accuracy=51.43\n",
            "=== learning_rate=0.1 : 3번째 훈련 완료  ===\n",
            " learning_rate=0.1일때의 accuracy 평균=58.25\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.01, epoch=3 : 1번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.2413, Train Accuracy: 92.58%\n",
            "  1. Test Accuracy: 94.41%\n",
            "Epoch [2/3], Loss: 0.1583, Train Accuracy: 95.55%\n",
            "  2. Test Accuracy: 95.13%\n",
            "Epoch [3/3], Loss: 0.1354, Train Accuracy: 96.17%\n",
            "  3. Test Accuracy: 95.63%\n",
            "=== learning_rate=0.01 : 1번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.01, epoch=3 : 2번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.2543, Train Accuracy: 92.41%\n",
            "  1. Test Accuracy: 95.11%\n",
            "Epoch [2/3], Loss: 0.1529, Train Accuracy: 95.55%\n",
            "  2. Test Accuracy: 93.22%\n",
            "Test Accuracy가 감소 : 훈련을 종료합니다. best_accuracy=95.11\n",
            "=== learning_rate=0.01 : 2번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.01, epoch=3 : 3번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.2551, Train Accuracy: 92.23%\n",
            "  1. Test Accuracy: 94.87%\n",
            "Epoch [2/3], Loss: 0.1583, Train Accuracy: 95.41%\n",
            "  2. Test Accuracy: 95.60%\n",
            "Epoch [3/3], Loss: 0.1372, Train Accuracy: 96.08%\n",
            "  3. Test Accuracy: 96.50%\n",
            "=== learning_rate=0.01 : 3번째 훈련 완료  ===\n",
            " learning_rate=0.01일때의 accuracy 평균=95.75\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.001, epoch=3 : 1번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.3195, Train Accuracy: 90.80%\n",
            "  1. Test Accuracy: 94.75%\n",
            "Epoch [2/3], Loss: 0.1440, Train Accuracy: 95.72%\n",
            "  2. Test Accuracy: 96.37%\n",
            "Epoch [3/3], Loss: 0.1000, Train Accuracy: 97.05%\n",
            "  3. Test Accuracy: 97.01%\n",
            "=== learning_rate=0.001 : 1번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.001, epoch=3 : 2번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.3189, Train Accuracy: 90.78%\n",
            "  1. Test Accuracy: 95.10%\n",
            "Epoch [2/3], Loss: 0.1459, Train Accuracy: 95.75%\n",
            "  2. Test Accuracy: 96.27%\n",
            "Epoch [3/3], Loss: 0.1045, Train Accuracy: 96.97%\n",
            "  3. Test Accuracy: 97.08%\n",
            "=== learning_rate=0.001 : 2번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.001, epoch=3 : 3번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.3203, Train Accuracy: 90.83%\n",
            "  1. Test Accuracy: 95.21%\n",
            "Epoch [2/3], Loss: 0.1484, Train Accuracy: 95.61%\n",
            "  2. Test Accuracy: 96.60%\n",
            "Epoch [3/3], Loss: 0.1036, Train Accuracy: 96.97%\n",
            "  3. Test Accuracy: 97.06%\n",
            "=== learning_rate=0.001 : 3번째 훈련 완료  ===\n",
            " learning_rate=0.001일때의 accuracy 평균=97.05\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.0001, epoch=3 : 1번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.7851, Train Accuracy: 80.89%\n",
            "  1. Test Accuracy: 90.27%\n",
            "Epoch [2/3], Loss: 0.3444, Train Accuracy: 90.45%\n",
            "  2. Test Accuracy: 91.54%\n",
            "Epoch [3/3], Loss: 0.2854, Train Accuracy: 91.92%\n",
            "  3. Test Accuracy: 92.58%\n",
            "=== learning_rate=0.0001 : 1번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.0001, epoch=3 : 2번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.7902, Train Accuracy: 81.75%\n",
            "  1. Test Accuracy: 90.18%\n",
            "Epoch [2/3], Loss: 0.3453, Train Accuracy: 90.38%\n",
            "  2. Test Accuracy: 91.74%\n",
            "Epoch [3/3], Loss: 0.2851, Train Accuracy: 91.87%\n",
            "  3. Test Accuracy: 92.70%\n",
            "=== learning_rate=0.0001 : 2번째 훈련 완료  ===\n",
            "------------------------------------------------------------\n",
            "learning_rate=0.0001, epoch=3 : 3번째 학습 실행\n",
            "Epoch [1/3], Loss: 0.7932, Train Accuracy: 80.99%\n",
            "  1. Test Accuracy: 89.95%\n",
            "Epoch [2/3], Loss: 0.3422, Train Accuracy: 90.59%\n",
            "  2. Test Accuracy: 91.66%\n",
            "Epoch [3/3], Loss: 0.2833, Train Accuracy: 91.95%\n",
            "  3. Test Accuracy: 92.72%\n",
            "=== learning_rate=0.0001 : 3번째 훈련 완료  ===\n",
            " learning_rate=0.0001일때의 accuracy 평균=92.67\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from models import MLP\n",
        "\n",
        "# 하이퍼파라미터 및 디바이스 설정\n",
        "batch_size = 128\n",
        "test_batch_size = 1000\n",
        "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4]\n",
        "nb_epochs = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# MNIST 데이터셋 로딩\n",
        "mnist = load_dataset(\"mnist\")\n",
        "\n",
        "# 데이터셋의 평균과 표준편차 계산 (정규화용)\n",
        "sample_data = torch.stack([\n",
        "    transforms.ToTensor()(mnist['train'][i]['image'])\n",
        "    for i in range(1000)\n",
        "])\n",
        "mean = sample_data.mean().item()\n",
        "std = sample_data.std().item()\n",
        "\n",
        "# Transform 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((mean,), (std,))\n",
        "])\n",
        "\n",
        "# 데이터 변환 함수 정의\n",
        "def transform_dataset(dataset):\n",
        "    \"\"\"데이터셋에 변환을 적용하는 함수\"\"\"\n",
        "    def transform_fn(batch):\n",
        "        # 이미지를 텐서로 변환하고 28x28을 784로 평탄화\n",
        "        images = [transform(img).view(-1) for img in batch[\"image\"]]\n",
        "        return {\n",
        "            \"image\": torch.stack(images),\n",
        "            \"label\": torch.tensor(batch[\"label\"])\n",
        "        }\n",
        "    return dataset.with_transform(transform_fn)\n",
        "\n",
        "# 훈련/테스트 데이터셋에 변환 적용\n",
        "train_dataset = transform_dataset(mnist[\"train\"])\n",
        "test_dataset = transform_dataset(mnist[\"test\"])\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=test_batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "for learning_rate in learning_rates:\n",
        "    repetition = 3\n",
        "    sum_of_accuray = 0 # n번 반복하여 나오는 best_accuracies의 평균을 구하기 위함.\n",
        "\n",
        "    for i in range (repetition):\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"learning_rate={learning_rate}, epoch={nb_epochs} : {i+1}번째 학습 실행\")\n",
        "        # 모델, 손실함수, 최적화기 설정\n",
        "        model = MLP().to(device)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "        best_test_acc = 0\n",
        "\n",
        "        # 훈련 루프 실행\n",
        "        for epoch in range(nb_epochs):\n",
        "            # 훈련 모드\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct_train = 0\n",
        "            total_train = 0\n",
        "\n",
        "            for batch_idx, batch in enumerate(train_loader):\n",
        "                imgs = batch[\"image\"].to(device)\n",
        "                labels = batch[\"label\"].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = model(imgs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total_train += labels.size(0)\n",
        "                correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "            # 에포크별 훈련 결과 출력\n",
        "            epoch_loss = running_loss / len(train_loader)\n",
        "            epoch_train_acc = 100 * correct_train / total_train\n",
        "            print(f\"Epoch [{epoch+1}/{nb_epochs}], Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_train_acc:.2f}%\")\n",
        "\n",
        "            # 테스트 정확도 계산\n",
        "            model.eval()\n",
        "            correct_test = 0\n",
        "            total_test = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in test_loader:\n",
        "                    imgs = batch[\"image\"].to(device)\n",
        "                    labels = batch[\"label\"].to(device)\n",
        "\n",
        "                    outputs = model(imgs)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total_test += labels.size(0)\n",
        "                    correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "            test_acc = 100 * correct_test / total_test\n",
        "            print(f\"  {epoch+1}. Test Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "            # Early Stopping\n",
        "            if test_acc > best_test_acc:\n",
        "                best_test_acc = test_acc\n",
        "            else:\n",
        "                print(f\"Test Accuracy가 감소 : 훈련을 종료합니다. best_accuracy={best_test_acc}\") # 한 epoch 전 모델을 저장해야 가장 뛰어난 성능의 모델을 저장할 수 있으나, 간단한 실험이 목적이므로 모델 저장은 생략함\n",
        "                break\n",
        "\n",
        "        sum_of_accuray += best_test_acc\n",
        "        print(f\"=== learning_rate={learning_rate} : {i+1}번째 훈련 완료  ===\")\n",
        "\n",
        "    print(f\" learning_rate={learning_rate}일때의 accuracy 평균={sum_of_accuray / repetition:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
