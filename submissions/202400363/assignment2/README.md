# MNIST 분류 실험 결과

## 기본 모델 성능
- 최종 테스트 정확도: 96.95%
- 훈련 시간: (실험 시 기록한 시간)
- 기본 모델의 하이퍼파라미터: 학습률 1e-3, 은닉층 크기 100, 에포크 3

---

## 실험 결과

### 실험 1: 하이퍼파라미터 튜닝 (학습률 변경)
- 변경사항: 학습률을 기본 모델의 `1e-3`에서 `1e-2`로 10배 높여서 훈련.
- 결과: 최종 테스트 정확도 94.98%로, 기본 모델보다 성능이 하락함.
- 분석: 학습률이 너무 높아서 모델의 학습이 불안정해지고, 최적점에 도달하지 못하고 발산하거나 튕겨나갔을 가능성이 높다. 이로 인해 정확도가 오히려 낮아진 것으로 보인다.

---

### 실험 2: 하이퍼파라미터 튜닝 (은닉층 크기 변경)
- 변경사항: 은닉층의 크기를 `100`에서 `200`으로 늘려서 훈련.
- 결과: 최종 테스트 정확도 93.49%로, 기본 모델보다 성능이 하락함.
- 분석: 은닉층의 크기를 늘렸지만, 학습률과 에포크 수가 기본 모델과 동일하여 모델의 복잡한 표현력을 충분히 학습하지 못하고 최적의 성능을 내지 못한 것으로 보인다.

---

### 실험 3: 모델 구조 개선 (은닉층 추가)
- 변경사항: 은닉층을 1개에서 2개로 추가하여 `MLP(784 -> 200 -> 100 -> 10)` 구조로 변경하고, 에포크 수를 `3`에서 `5`로 늘려서 훈련.
- 결과: 최종 테스트 정확도 95.41%를 달성함.
- 분석: 에포크를 늘려 충분히 학습시켰음에도 불구하고, 기본 모델보다 정확도가 소폭 낮았다. 이는 추가된 은닉층이 복잡도를 높여 더 많은 데이터를 필요로 하거나, 하이퍼파라미터 튜닝이 추가적으로 필요함을 시사한다.

---

## 결론 및 인사이트
- 가장 효과적인 개선 방법: 제공된 실험 결과만 보면 기본 모델의 성능이 가장 높았다. 이는 기본 모델의 설정이 MNIST 데이터셋에 잘 맞춰져 있음을 의미한다.
- 관찰된 패턴: 학습률을 높이거나 모델의 복잡도를 급격히 늘리면 오히려 성능이 하락할 수 있다. 모델의 성능을 향상시키기 위해서는 하이퍼파라미터와 구조를 신중하게 조절하고, 충분한 시간을 두고 학습시켜야 한다.
- 추가 개선 아이디어:
    1.  은닉층 크기를 더 미세하게 조절하거나 다른 학습률로 추가 실험을 해볼 수 있다.
    2.  `Dropout`을 추가하여 과적합을 방지하는 실험을 진행해볼 수 있다.